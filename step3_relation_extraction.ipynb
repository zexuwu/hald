{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1a8fd70-62dc-44e9-a5f4-544936c4aec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/hald/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json, stanza, pickle, datetime, time, re, os, random, pymongo, csv, copy, sys, \\\n",
    "allennlp_models.structured_prediction, \n",
    "from multiprocessing import Process, Manager, Pool\n",
    "from pymongo import MongoClient\n",
    "import pandas as pd\n",
    "from allennlp.predictors.predictor import Predictor\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import mpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "491ec003-c1b0-4256-a1d1-1b9d0f1b8eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient(username=\"hald\",password=\"mclab236\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc362a6a-db48-4218-8983-ffe1a8ea71f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "now=datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8f2dca7-9cf8-46c0-af3b-ff608d101b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "now_time=now.strftime('%Y_%m_%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f942af9-73ad-496e-afc3-bf76b8e622e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2023_05_09'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "now_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0dd2f47e-ca4f-4a9c-9e07-d2523ce7bca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs=['Gene','RNA','Carbohydrate','Lipid','Peptide', 'Pharmaceutical_Preparations', 'Protein', 'Toxin','Mutation', 'Disease']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50946dcc-3f9b-4855-81a0-025f4115a01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = client.hald"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ee2a2be-dc83-4f0c-9474-9d1b54fd661e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Gene_entities=list(db.Gene_raw.find({'addtime':now_time}))\n",
    "RNA_entities=list(db.RNA_raw.find({'addtime':now_time}))\n",
    "Carbohydrate_entities=list(db.Carbohydrate_raw.find({'addtime':now_time}))\n",
    "Lipid_entities=list(db.Lipid_raw.find({'addtime':now_time}))\n",
    "Peptide_entities=list(db.Peptide_raw.find({'addtime':now_time}))\n",
    "Pharmaceutical_Preparations_entities=list(db.Pharmaceutical_Preparations_raw.find({'addtime':now_time}))\n",
    "Protein_entities=list(db.Protein_raw.find({'addtime':now_time}))\n",
    "Toxin_entities=list(db.Toxin_raw.find({'addtime':now_time}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df37f7c8-a439-4020-81a3-29dca29ee543",
   "metadata": {},
   "outputs": [],
   "source": [
    "Mutation_entities=[]\n",
    "Disease_entities=[]\n",
    "for i in list(db.Mutation_raw.find({'addtime':now_time})):\n",
    "    if i.get('Genomic View'):\n",
    "        Mutation_entities.append(i)\n",
    "for i in list(db.Disease_raw.find({'addtime':now_time})):\n",
    "    if i.get('url'):\n",
    "        Disease_entities.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31306d4b-4768-44de-adf4-565124f6c84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "names=locals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c2c4827-efaf-43d3-987a-3aed43c59e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1056\n",
      "32\n",
      "109\n",
      "72\n",
      "31\n",
      "1\n",
      "18\n",
      "2\n",
      "28\n",
      "7174\n"
     ]
    }
   ],
   "source": [
    "for i in pairs:\n",
    "    print(len(names[i+'_entities']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e537f307-f9ba-4354-90ee-ec745816788f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in pairs:\n",
    "    names[j+'_dict']={}\n",
    "    for i in names[j+'_entities']:\n",
    "        names[j+'_dict'][i.get('PMID')]=names[j+'_dict'].get(i.get('PMID'),[])+[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8487ff40-ed9f-4f77-9f0d-7b982977a4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_relation_dict={}\n",
    "for j in range(len(pairs)-1):\n",
    "    for i in range(j+1,len(pairs)):\n",
    "        for k in list(set(names[pairs[j]+'_dict'].keys()).intersection(set(names[pairs[i]+'_dict'].keys()))):\n",
    "            for l in names[pairs[j]+'_dict'].get(k):\n",
    "                for m in names[pairs[i]+'_dict'].get(k):\n",
    "                    if l.get('sentence')==m.get('sentence') and l.get('entity')!=m.get('entity'):\n",
    "                        diff_relation_dict[l.get('sentence')]=diff_relation_dict.get(l.get('sentence'),[])+[{'PMID':l.get('PMID'),\n",
    "                                                                                                  'entity1':l.get('entity'),\n",
    "                                                                                                   'entity2':m.get('entity'),\n",
    "                                                                                                   'sentence':l.get('sentence'),\n",
    "                                                                                                   'AB':l.get('AB'),\n",
    "                                                                                                   'target1':l.get('target'),\n",
    "                                                                                                    'target1_type':l.get('type'),\n",
    "                                                                                                   'target2':m.get('target'),\n",
    "                                                                                                    'target2_type':m.get('type'),\n",
    "                                                                                                   'PMID':l.get('PMID'),\n",
    "                                                                                                  }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9b257bb-dad1-4ebf-8d29-d16147177c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "same_relation_dict={}\n",
    "for j in range(len(pairs)):\n",
    "    for k in names[pairs[j]+'_dict'].values():\n",
    "        for l in range(len(k)-1):\n",
    "            for m in range(l+1,len(k)):\n",
    "                if k[l].get('sentence')==k[m].get('sentence'):\n",
    "                    if k[l].get('entity')!=k[m].get('entity'):\n",
    "                        same_relation_dict[k[l].get('sentence')]=same_relation_dict.get(k[l].get('sentence'),[])+[{'PMID':k[l].get('PMID'),\n",
    "                                                                                                  'entity1':k[l].get('entity'),\n",
    "                                                                                                   'entity2':k[m].get('entity'),\n",
    "                                                                                                   'sentence':k[l].get('sentence'),\n",
    "                                                                                                   'AB':k[l].get('AB'),\n",
    "                                                                                                   'target1':k[l].get('target'),\n",
    "                                                                                                    'target1_type':k[l].get('type'),\n",
    "                                                                                                   'target2':k[m].get('target'),\n",
    "                                                                                                    'target2_type':k[l].get('type'),\n",
    "                                                                                                   'PMID':k[l].get('PMID'),\n",
    "                                                                                                  }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f41b4a54-9a74-4461-9a95-e1348235d4ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1408\n",
      "295\n",
      "98\n"
     ]
    }
   ],
   "source": [
    "print(len(same_relation_dict))\n",
    "print(len(diff_relation_dict))\n",
    "print(len(list(set(list(same_relation_dict.keys())).intersection(set(list(diff_relation_dict.keys()))))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dbd3342e-e8f9-4a32-8137-88a565984cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "relation_dict={}\n",
    "for i in same_relation_dict.keys():\n",
    "    if diff_relation_dict.get(i):\n",
    "        relation_dict[i]=same_relation_dict.get(i)+diff_relation_dict.get(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86c1cadd-1677-4c93-9010-9db21b0c966c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1408\n",
      "1605\n"
     ]
    }
   ],
   "source": [
    "for i in same_relation_dict.keys():\n",
    "    if not relation_dict.get(i):\n",
    "        relation_dict[i]=same_relation_dict.get(i)\n",
    "print(len(relation_dict))\n",
    "for i in diff_relation_dict.keys():\n",
    "    if not relation_dict.get(i):\n",
    "        relation_dict[i]=diff_relation_dict.get(i)\n",
    "print(len(relation_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "62c04584-5af6-4c86-b707-092071032539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Materials and Methods: In this study, human astrocytes were employed to measure amyloid-beta (Abeta)-induced senescence features, including senescence-associated beta-galactosidase (SA-beta-gal), p16INK4A, p21WAF1, and p53.',\n",
       " [{'PMID': '36695672',\n",
       "   'entity1': 'TP53',\n",
       "   'entity2': 'CDKN2A',\n",
       "   'sentence': 'Materials and Methods: In this study, human astrocytes were employed to measure amyloid-beta (Abeta)-induced senescence features, including senescence-associated beta-galactosidase (SA-beta-gal), p16INK4A, p21WAF1, and p53.',\n",
       "   'AB': \"Introduction: As aging is the leading risk factor for Alzheimer's disease (AD), ablation of senescent cells is a promising therapeutic approach to prevent AD. It is known that astrocytes lose their ability to maintain a healthy brain environment when aging. Studies have recently shown that cannabidiol (CBD) provides a promising therapeutic avenue for AD; however, if or how CBD prevents astrocyte aging is not known. Materials and Methods: In this study, human astrocytes were employed to measure amyloid-beta (Abeta)-induced senescence features, including senescence-associated beta-galactosidase (SA-beta-gal), p16INK4A, p21WAF1, and p53. The effects of CBD on the production of mitochondrial dysfunction and mitophagy pathway were measured by Western blot and fluorescence assay. Caenorhabditis elegans was used as in vivo AD model to investigate the effects of CBD on life span and health span. All experimental procedures were approved by the Human Research Ethics Committee, University of Wollongong, Australia. Results: In human astrocytes, we show that treatment with Abeta, an endogenous pathogenic agent of AD, results in an increase in the percentage of SA-beta-gal-positive cells and induces mitochondrial reactive oxygen species (ROS). However, CBD treatment protects from Abeta-induced senescence. Furthermore, the anti-senescence and anti-apoptotic activities of CBD were observed to be mediated through the protective effect of Parkin-dependent mitophagy. In C. elegans, we used the transgenic GRU102 strain, which expresses the human Abeta peptide, and found that CBD treatment extended life span, improved pumping rate, and decreased mitochondrial ROS. Conclusion and Significance: Our results demonstrate that CBD prevents the human astrocyte senescence induced by Abeta by a mechanism involving the Parkin-mediated mitophagy pathway. Our findings support the new therapeutic avenues of CBD for the treatment of AD patients.\",\n",
       "   'target1': 'p53',\n",
       "   'target1_type': 'Gene',\n",
       "   'target2': 'p16INK4A',\n",
       "   'target2_type': 'Gene'},\n",
       "  {'PMID': '36695672',\n",
       "   'entity1': 'TP53',\n",
       "   'entity2': 'Gangliosidosis, GM1',\n",
       "   'sentence': 'Materials and Methods: In this study, human astrocytes were employed to measure amyloid-beta (Abeta)-induced senescence features, including senescence-associated beta-galactosidase (SA-beta-gal), p16INK4A, p21WAF1, and p53.',\n",
       "   'AB': \"Introduction: As aging is the leading risk factor for Alzheimer's disease (AD), ablation of senescent cells is a promising therapeutic approach to prevent AD. It is known that astrocytes lose their ability to maintain a healthy brain environment when aging. Studies have recently shown that cannabidiol (CBD) provides a promising therapeutic avenue for AD; however, if or how CBD prevents astrocyte aging is not known. Materials and Methods: In this study, human astrocytes were employed to measure amyloid-beta (Abeta)-induced senescence features, including senescence-associated beta-galactosidase (SA-beta-gal), p16INK4A, p21WAF1, and p53. The effects of CBD on the production of mitochondrial dysfunction and mitophagy pathway were measured by Western blot and fluorescence assay. Caenorhabditis elegans was used as in vivo AD model to investigate the effects of CBD on life span and health span. All experimental procedures were approved by the Human Research Ethics Committee, University of Wollongong, Australia. Results: In human astrocytes, we show that treatment with Abeta, an endogenous pathogenic agent of AD, results in an increase in the percentage of SA-beta-gal-positive cells and induces mitochondrial reactive oxygen species (ROS). However, CBD treatment protects from Abeta-induced senescence. Furthermore, the anti-senescence and anti-apoptotic activities of CBD were observed to be mediated through the protective effect of Parkin-dependent mitophagy. In C. elegans, we used the transgenic GRU102 strain, which expresses the human Abeta peptide, and found that CBD treatment extended life span, improved pumping rate, and decreased mitochondrial ROS. Conclusion and Significance: Our results demonstrate that CBD prevents the human astrocyte senescence induced by Abeta by a mechanism involving the Parkin-mediated mitophagy pathway. Our findings support the new therapeutic avenues of CBD for the treatment of AD patients.\",\n",
       "   'target1': 'p53',\n",
       "   'target1_type': 'Gene',\n",
       "   'target2': 'beta-galactosidase',\n",
       "   'target2_type': 'Disease'},\n",
       "  {'PMID': '36695672',\n",
       "   'entity1': 'CDKN2A',\n",
       "   'entity2': 'Gangliosidosis, GM1',\n",
       "   'sentence': 'Materials and Methods: In this study, human astrocytes were employed to measure amyloid-beta (Abeta)-induced senescence features, including senescence-associated beta-galactosidase (SA-beta-gal), p16INK4A, p21WAF1, and p53.',\n",
       "   'AB': \"Introduction: As aging is the leading risk factor for Alzheimer's disease (AD), ablation of senescent cells is a promising therapeutic approach to prevent AD. It is known that astrocytes lose their ability to maintain a healthy brain environment when aging. Studies have recently shown that cannabidiol (CBD) provides a promising therapeutic avenue for AD; however, if or how CBD prevents astrocyte aging is not known. Materials and Methods: In this study, human astrocytes were employed to measure amyloid-beta (Abeta)-induced senescence features, including senescence-associated beta-galactosidase (SA-beta-gal), p16INK4A, p21WAF1, and p53. The effects of CBD on the production of mitochondrial dysfunction and mitophagy pathway were measured by Western blot and fluorescence assay. Caenorhabditis elegans was used as in vivo AD model to investigate the effects of CBD on life span and health span. All experimental procedures were approved by the Human Research Ethics Committee, University of Wollongong, Australia. Results: In human astrocytes, we show that treatment with Abeta, an endogenous pathogenic agent of AD, results in an increase in the percentage of SA-beta-gal-positive cells and induces mitochondrial reactive oxygen species (ROS). However, CBD treatment protects from Abeta-induced senescence. Furthermore, the anti-senescence and anti-apoptotic activities of CBD were observed to be mediated through the protective effect of Parkin-dependent mitophagy. In C. elegans, we used the transgenic GRU102 strain, which expresses the human Abeta peptide, and found that CBD treatment extended life span, improved pumping rate, and decreased mitochondrial ROS. Conclusion and Significance: Our results demonstrate that CBD prevents the human astrocyte senescence induced by Abeta by a mechanism involving the Parkin-mediated mitophagy pathway. Our findings support the new therapeutic avenues of CBD for the treatment of AD patients.\",\n",
       "   'target1': 'p16INK4A',\n",
       "   'target1_type': 'Gene',\n",
       "   'target2': 'beta-galactosidase',\n",
       "   'target2_type': 'Disease'}])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(relation_dict.items())[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68994520-d80a-4000-873d-ab879484ea76",
   "metadata": {},
   "outputs": [],
   "source": [
    "relation_list=[]\n",
    "for i in relation_dict.values():\n",
    "    for j in i:\n",
    "        relation_list.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ebe28a-9e1f-443f-bec7-5149adf2c50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "colons=[]\n",
    "not_colons=[]\n",
    "for i in relation_list:\n",
    "    if not re.search(':',i.get('sentence')[:50],flags=re.M|re.I):\n",
    "        if re.search('\\snot\\s',i.get('sentence'),flags=re.M|re.I):\n",
    "            not_colons.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69908912-5404-459f-bb78-57a7835eaabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(not_colons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc6696d-f155-43c3-a39a-a311704e5cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_colons[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad96a145-53a7-414b-91d8-478c8c17ad1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "colons=[]\n",
    "triplelist_filtered=[]\n",
    "for i in triplelist:\n",
    "    if re.search(':',i.get('sentence')[:50],flags=re.M|re.I):\n",
    "        colons.append(copy.deepcopy(i))\n",
    "    else:\n",
    "        triplelist_filtered.append(copy.deepcopy(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994e119c-c33b-4e1c-ad8d-a4dfcb0d2bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(triplelist))\n",
    "print(len(colons))\n",
    "print(len(triplelist_filtered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95315b2b-d232-4730-bb36-075e8b7479e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_with_colons=[]\n",
    "sentences_with_colons_set=set()\n",
    "sentences_without_colons=[]\n",
    "sentences_with_colons_dict={}\n",
    "sentences_without_colons_dict={}\n",
    "for i in colons:\n",
    "    sentences_with_colons_dict[i.get('sentence')]=sentences_with_colons_dict.get(i.get('sentence'),[])+[copy.deepcopy(i)]\n",
    "    if not re.match(r'(result(s)?: )|(objective(s)?: )|(method(s)?: )|(background(s)?: )|(purpose(s)?: )|(conclusion(s)?: )|(introduction(s)?: )|(participants(s)?: )|(aim(s)?: )|(importance(s)?: )|(discussion(s)?: )|(abstract(s)?: )|(recent finding(s)?: )|([A-Z]+: )|([A-Z]+\\(S\\): )|(([A-Z]+\\s(&\\s)?)*[A-Z]+: )|(([A-Z]+\\/)*[A-Z]+: )',i.get('sentence'),flags=re.M|re.I):\n",
    "        sentences_with_colons.append(i.get('sentence'))\n",
    "        sentences_with_colons_set.add(i.get('sentence'))\n",
    "    else:\n",
    "        sentences_without_colons.append(re.sub(r'(result(s)?: )|(objective(s)?: )|(method(s)?: )|(background(s)?: )|(purpose(s)?: )|(conclusion(s)?: )|(introduction(s)?: )|(participants(s)?: )|(aim(s)?: )|(importance(s)?: )|(discussion(s)?: )|(abstract(s)?: )|(recent finding(s)?: )|([A-Z]+: )|([A-Z]+\\(S\\): )|(([A-Z]+\\s(&\\s)?)*[A-Z]+: )|(([A-Z]+\\/)*[A-Z]+: )','',copy.deepcopy(i).get('sentence'),flags=re.M|re.I))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3867191a-cf00-4e27-ac2f-357fb0df553c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_without_colons[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1966aae5-8cbd-48a1-999f-0ac29b839b93",
   "metadata": {},
   "source": [
    "## List sentences_with_colons_set and define sentences_with_colons_filtered with normalized sentences!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbec7331-3f58-4797-a1f1-85bbafd4a4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_with_colons_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb4483e-f2a5-4a58-a6f4-13ecebb5d38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to redefine!!!\n",
    "sentences_with_colons_filtered=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5077f2a-7c7f-4ad0-8ffa-1fb91d4844ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_with_colons_filtered=sentences_with_colons_filtered+sentences_without_colons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb163457-c340-4922-a2e7-adf8e7f2ed19",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sentences_with_colons_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ddc73f-bfa0-4424-83c4-97d642dce039",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_colons={}\n",
    "for i in sentences_with_colons_filtered:\n",
    "    for j,k in sentences_with_colons_dict.items():\n",
    "        if i[-50:-1]==j[-50:-1]:\n",
    "            for l in k:\n",
    "                l.update({'sentence_transformed':i})\n",
    "            sentence_colons[i]=k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a2e29b-8c63-4a12-9db0-784d916ca4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sentence_colons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fc3fe9-a9c9-44c0-840d-c206bca78f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sentences_with_colons_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9248bd63-fe10-49ec-bba3-525aa680fb57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda201a3-0a4b-4516-aebb-db75d0e12bde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "748d1a0c-ee3f-4257-bf75-89719c7f1b72",
   "metadata": {},
   "source": [
    "## Prepare for OpenIE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2aac8d38-5d06-4d06-9043-ed0705abf934",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('results/step3/openie/filelist/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d2511a9a-d4c6-4c38-96db-35787a4ef3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind=1\n",
    "for i in sentences_with_colons_filtered:\n",
    "    f=open('results/step3/openie/filelist/sentence'+str(ind)+'.txt','w')\n",
    "    f.write(i)\n",
    "    f.close()\n",
    "    ind+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5254764a-7500-4934-8f98-e5364ad89f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open('results/step3/openie/filelist.txt','a')\n",
    "for i in range(1,len(sentences_with_colons_filtered)+1):\n",
    "    f.write('filelist/sentence'+str(i)+'.txt'+'\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00172ab5-be92-4a9e-8b7e-11594a0c1a4c",
   "metadata": {},
   "source": [
    "### Run in shell "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5307f23c-f91b-439f-b47a-ba6869a98994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cd results/step3/openie\n",
    "# nohup java -mx500g -cp ../../../../stanza_corenlp/stanford-corenlp-4.3.2.jar:../../../../stanza_corenlp/stanford-corenlp-4.3.2-models.jar:../../../../stanza_corenlp/CoreNLP-to-HTML.xsl:../../../../slf4j-api.jar:../../../../stanza_corenlp/slf4j-simple.jar edu.stanford.nlp.naturalli.OpenIE -format reverb -filelist ./filelist.txt -output ./openie.txt > ./openie.log &\n",
    "# cd ../../../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d396a1-aedb-4408-83f0-3c85debf7233",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab8644d-d552-45b4-945a-2344117cda2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "31421ca3-2bc1-4ce5-b431-a247d177b3a5",
   "metadata": {},
   "source": [
    "## Prepare for Stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73cd0f0-33bf-4cb9-9b99-fc48606caef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('results/step3/openie/files/')\n",
    "k=1\n",
    "for i in range(0,len(sentences_with_colons_filtered),len(sentences_with_colons_filtered)//4):\n",
    "    pickle.dump(sentences_with_colons_filtered[i:i+len(sentences_with_colons_filtered)//4],open('results/step3/openie/files/openie'+str(k)+'.pkl','wb'))\n",
    "    k+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2147fe52-283e-4a20-93b9-1d558ef2b812",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.makedirs('results/step3/rules/files/')\n",
    "k=1\n",
    "for i in range(0,len(sentences_with_colons_filtered),len(sentences_with_colons_filtered)//4):\n",
    "    f=open('results/step3/rules/files/rules'+str(k)+'.py','w')\n",
    "    f.write('''\n",
    "import stanza\n",
    "import os\n",
    "import datetime\n",
    "import time\n",
    "nlp = stanza.Pipeline('en', package='genia',download_method=None)\n",
    "import pickle\n",
    "raw=pickle.load(open('../../openie/files/openie'''+str(k)+'''.pkl','rb'))\n",
    "import re \n",
    "\n",
    "def nlpSentence(i,sentence2words,sentence2relations,sentence2verblist,sentence2verbtype,sentence2adv):\n",
    "    sentence=i\n",
    "    doc=nlp(sentence)\n",
    "    words=[]\n",
    "    for sent in doc.sentences:\n",
    "        for word in sent.words:\n",
    "            words.append(word.text)\n",
    "    relations=[]\n",
    "    verblist=[]\n",
    "    verbprototype=[]\n",
    "    adv=[]\n",
    "    for sent in doc.sentences:\n",
    "        for word in sent.words:\n",
    "            relations.append([word.text,words[int(word.head)-1],int(word.id),int(word.head),word.deprel,word.xpos])\n",
    "            if word.xpos in ['VB','VBD','VBG','VBN', 'VBP', 'VBZ']:\n",
    "                verblist.append({word.text:word.xpos})\n",
    "                verbprototype.append({word.text:word.lemma})\n",
    "            if word.xpos in ['RB','RBR','RBS']:\n",
    "                adv.append({word.text:word.xpos})\n",
    "    sentence2words[i]=words\n",
    "    sentence2relations[i]=relations\n",
    "    sentence2verblist[i]=verblist\n",
    "    sentence2verbprototype[i]=verbprototype\n",
    "    sentence2adv[i]=adv\n",
    "\n",
    "\n",
    "start=datetime.datetime.now()\n",
    "print('Parent process %s.' % os.getpid())\n",
    "sentence2words={}\n",
    "sentence2relations={}\n",
    "sentence2verblist={}\n",
    "sentence2verbprototype={}\n",
    "sentence2adv={}\n",
    "for i in raw:\n",
    "    nlpSentence(i,sentence2words,sentence2relations,sentence2verblist,sentence2verbprototype,sentence2adv)\n",
    "pickle.dump(sentence2words,open('sentence2words'''+str(k)+'''.pkl','wb'))\n",
    "pickle.dump(sentence2relations,open('sentence2relations'''+str(k)+'''.pkl','wb'))\n",
    "pickle.dump(sentence2verblist,open('sentence2verblist'''+str(k)+'''.pkl','wb'))\n",
    "pickle.dump(sentence2verbprototype,open('sentence2verbprototype'''+str(k)+'''.pkl','wb'))\n",
    "pickle.dump(sentence2adv,open('sentence2adv'''+str(k)+'''.pkl','wb'))\n",
    "print('Waiting for all subprocesses done...')\n",
    "\n",
    "end=datetime.datetime.now()\n",
    "print(\"The running time is \"+str((end-start).seconds)+\"s\")  \n",
    "    ''')\n",
    "    f.close()\n",
    "    k+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5dd8648-c853-4746-951e-972d8767d000",
   "metadata": {},
   "source": [
    "### Run in shell "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "6e7d76fa-9657-409f-99db-7bbf3c0adb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cd rules/files\n",
    "# for i in {1..5}; do echo \"nohup python rules${i}.py >> rules.log &\" | bash; done\n",
    "# cd ../../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e810049e-8964-40bc-a86f-fa1dee22fa01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484e2d57-4bb4-4589-a739-310cd2ff697e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4f225069-3458-4dd2-8b98-152f8cd10f23",
   "metadata": {},
   "source": [
    "# Deal with OpenIE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "19218ca8-b103-4822-ba93-4663dd79d69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "openie_table=pd.read_table('results/step3/openie/openie.txt',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cc7ed1c3-0f04-45b4-a9ac-088ad1371e71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>filelist/sentence47.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>TGFBR2 variants</td>\n",
       "      <td>were</td>\n",
       "      <td>found</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TGFBR2 variants were found in 7 ( 7.6 % ) pati...</td>\n",
       "      <td>NN NNS VBD VBN IN CD -LRB- CD NN -RRB- NNS IN ...</td>\n",
       "      <td>tgfbr2 variant</td>\n",
       "      <td>be</td>\n",
       "      <td>find</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>filelist/sentence47.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>7 patients</td>\n",
       "      <td>is with</td>\n",
       "      <td>three V216I</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TGFBR2 variants were found in 7 ( 7.6 % ) pati...</td>\n",
       "      <td>NN NNS VBD VBN IN CD -LRB- CD NN -RRB- NNS IN ...</td>\n",
       "      <td>7 patient</td>\n",
       "      <td>be with</td>\n",
       "      <td>three v216i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>filelist/sentence120.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>CONCLUSION</td>\n",
       "      <td>associated with</td>\n",
       "      <td>increased risk of recurrent cardiovascular events</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>26</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CONCLUSION : The most frequent CHIP - related ...</td>\n",
       "      <td>NN : DT RBS JJ NN HYPH VBN NNS , NN , NN , CC ...</td>\n",
       "      <td>conclusion</td>\n",
       "      <td>associate with</td>\n",
       "      <td>increase risk of recurrent cardiovascular event</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>filelist/sentence33.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>NR1D1 BMAL1 ratio</td>\n",
       "      <td>was significantly higher in</td>\n",
       "      <td>morning deaths</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The NR1D1 / BMAL1 ratio was significantly high...</td>\n",
       "      <td>DT NN HYPH NN NN VBD RB JJR IN NN NNS CC DT NN...</td>\n",
       "      <td>nr1d1 bmal1 ratio</td>\n",
       "      <td>be significantly higher in</td>\n",
       "      <td>morning death</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>filelist/sentence33.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>NR1D1 BMAL1 ratio</td>\n",
       "      <td>was</td>\n",
       "      <td>higher</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The NR1D1 / BMAL1 ratio was significantly high...</td>\n",
       "      <td>DT NN HYPH NN NN VBD RB JJR IN NN NNS CC DT NN...</td>\n",
       "      <td>nr1d1 bmal1 ratio</td>\n",
       "      <td>be</td>\n",
       "      <td>higher</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         0   1                  2   \\\n",
       "0   filelist/sentence47.txt   0    TGFBR2 variants   \n",
       "1   filelist/sentence47.txt   0         7 patients   \n",
       "2  filelist/sentence120.txt   0         CONCLUSION   \n",
       "3   filelist/sentence33.txt   0  NR1D1 BMAL1 ratio   \n",
       "4   filelist/sentence33.txt   0  NR1D1 BMAL1 ratio   \n",
       "\n",
       "                            3   \\\n",
       "0                         were   \n",
       "1                      is with   \n",
       "2              associated with   \n",
       "3  was significantly higher in   \n",
       "4                          was   \n",
       "\n",
       "                                                  4   5   6   7   8   9   10  \\\n",
       "0                                              found   0   2   2   3   3   4   \n",
       "1                                        three V216I   5  11  11  12  12  14   \n",
       "2  increased risk of recurrent cardiovascular events   0   1  18  20  20  26   \n",
       "3                                     morning deaths   1   5   5   9   9  11   \n",
       "4                                             higher   1   5   5   6   7   8   \n",
       "\n",
       "    11                                                 12  \\\n",
       "0  1.0  TGFBR2 variants were found in 7 ( 7.6 % ) pati...   \n",
       "1  1.0  TGFBR2 variants were found in 7 ( 7.6 % ) pati...   \n",
       "2  1.0  CONCLUSION : The most frequent CHIP - related ...   \n",
       "3  1.0  The NR1D1 / BMAL1 ratio was significantly high...   \n",
       "4  1.0  The NR1D1 / BMAL1 ratio was significantly high...   \n",
       "\n",
       "                                                  13                 14  \\\n",
       "0  NN NNS VBD VBN IN CD -LRB- CD NN -RRB- NNS IN ...     tgfbr2 variant   \n",
       "1  NN NNS VBD VBN IN CD -LRB- CD NN -RRB- NNS IN ...          7 patient   \n",
       "2  NN : DT RBS JJ NN HYPH VBN NNS , NN , NN , CC ...         conclusion   \n",
       "3  DT NN HYPH NN NN VBD RB JJR IN NN NNS CC DT NN...  nr1d1 bmal1 ratio   \n",
       "4  DT NN HYPH NN NN VBD RB JJR IN NN NNS CC DT NN...  nr1d1 bmal1 ratio   \n",
       "\n",
       "                           15                                               16  \n",
       "0                          be                                             find  \n",
       "1                     be with                                      three v216i  \n",
       "2              associate with  increase risk of recurrent cardiovascular event  \n",
       "3  be significantly higher in                                    morning death  \n",
       "4                          be                                           higher  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openie_table.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f126fbbf-b1ac-443f-9ea4-5b501654a6ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24641"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(openie_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "feb785ec-5d25-49e6-a781-f8fd3ea7b631",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=openie_table.loc[:,[0,2,3,4,12]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0dc9a59d-3956-4858-b6b1-515be2bf51c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "be=['be','am','is','are','was','were','have been','has been']\n",
    "bedict={}\n",
    "for i in be:\n",
    "    bedict[i]='be'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7cec02c6-1a29-4cef-bf92-8416629a3658",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in rules_pairs:\n",
    "    names[i]={}\n",
    "    for k in ['results/step3/rules/files/'+i+str(j)+'.pkl' for j in range(1,6)]:\n",
    "        names[i].update(pickle.load(open(k,'rb')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b88f59b6-1ad5-4955-b4ea-939141710eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "finallist=[]\n",
    "for line in range(len(df)):\n",
    "    i=sentences_with_colons_filtered[int(df.iloc[line,0][17:-4])-1]\n",
    "    verblist=sentence2verblist.get(i)\n",
    "    verbrelation=''\n",
    "    real_verb=''\n",
    "    verbdict={}\n",
    "    verbs_split=df.loc[line,3].split(' ')\n",
    "    for verb in verblist:\n",
    "        verbdict.update(verb)\n",
    "    for indexx,one in enumerate(verbs_split):\n",
    "        if verbdict.get(one):\n",
    "            verbrelation=one\n",
    "            relations=sentence2relations.get(i)\n",
    "            relations_display=[relation[-2] for relation in relations]\n",
    "            verbprototype=sentence2verbprototype.get(i)\n",
    "            verbprototype_dict={}\n",
    "            for verbp in verbprototype:\n",
    "                verbprototype_dict.update(verbp)\n",
    "            for index_passive,passive in enumerate(relations_display):\n",
    "                if passive=='aux:pass':\n",
    "                    if relations[index_passive][1]==verbrelation:\n",
    "                        verb_prototype=verbrelation\n",
    "                        break\n",
    "                elif passive=='acl' and relations[index_passive][-1]=='VBN':\n",
    "                    if relations[index_passive][0]==verbrelation:\n",
    "                        verb_prototype=verbrelation\n",
    "                        break\n",
    "            else:\n",
    "                for v in verbprototype:\n",
    "                    if v.get(verbrelation):\n",
    "                        verb_prototype=v.get(verbrelation)\n",
    "                        break\n",
    "            verbs_split[indexx]=verb_prototype\n",
    "        elif bedict.get(one):\n",
    "            verbs_split[indexx]=bedict.get(one)\n",
    "    if bedict.get(' '.join(verbs_split[:2])):\n",
    "        final=' '.join(['be']+verbs_split[2:])\n",
    "    else:\n",
    "        final=' '.join(verbs_split)\n",
    "    finallist.append(final)\n",
    "df[17]=finallist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "73bf420d-b083-4f93-9334-bd2dd4f4aace",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind=1\n",
    "for i in relation_dict.keys():\n",
    "    names['sentence'+str(ind)]=i\n",
    "    ind+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d30b7954-ec30-48e0-bda0-ce2990e768a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "relation_dict_copy=copy.deepcopy(sentence_colons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7d51bfe4-1a83-4040-82bd-fbca19ec6439",
   "metadata": {},
   "outputs": [],
   "source": [
    "suc=[]\n",
    "for i in range(1,len(relation_dict_copy)+1):\n",
    "    if relation_dict_copy.get(names[df.iloc[i-1,0][9:-4]]):\n",
    "        openie=[]\n",
    "        for j in relation_dict_copy.get(names[df.iloc[i-1,0][9:-4]]):\n",
    "            j1=j.get('target1').translate(str.maketrans({\"-\":  r\"\\-\",\"\\\\\": r\"\\\\\", \"^\":  r\"\\^\",\"$\":  r\"\\$\",\"*\":  r\"\\*\",\".\":  r\"\\.\",\"(\":  r\"\\(\",\")\":  r\"\\)\",\"+\":  r\"\\+\",\"[\":  r\"\\[\",\"]\":  r\"\\]\",\n",
    "                      \"{\":  r\"\\{\",\"}\":  r\"\\}\",\"|\":  r\"\\|\",\"?\":  r\"\\?\"}))\n",
    "            j2=j.get('target2').translate(str.maketrans({\"-\":  r\"\\-\",\"\\\\\": r\"\\\\\", \"^\":  r\"\\^\",\"$\":  r\"\\$\",\"*\":  r\"\\*\",\".\":  r\"\\.\",\"(\":  r\"\\(\",\")\":  r\"\\)\",\"+\":  r\"\\+\",\"[\":  r\"\\[\",\"]\":  r\"\\]\",\n",
    "                      \"{\":  r\"\\{\",\"}\":  r\"\\}\",\"|\":  r\"\\|\",\"?\":  r\"\\?\"}))\n",
    "            if re.search(j1,df.iloc[i-1,1]) and re.search(j2,df.iloc[i-1,3]):\n",
    "                j['openie']=j.get('openie',[])+[[j.get('target1'),df.iloc[i-1,-1],j.get('target2')]]\n",
    "                openie.append([j.get('target1'),df.iloc[i-1,-1],j.get('target2')])\n",
    "            elif re.search(j2,df.iloc[i-1,1]) and re.search(j1,df.iloc[i-1,3]):\n",
    "                j['openie']=j.get('openie',[])+[[j.get('target2'),df.iloc[i-1,-1],j.get('target1')]]\n",
    "                openie.append([j.get('target2'),df.iloc[i-1,-1],j.get('target1')]) \n",
    "        if not openie:\n",
    "            suc.append(names[df.iloc[i-1,0][9:-4]])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "70d7b0ec-39b7-4fbe-90f7-beed4f3c42a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "error=[]\n",
    "for i in range(1,len(relation_dict_copy)+1):\n",
    "    if not relation_dict_copy.get(names[df.iloc[i-1,0][9:-4]]):\n",
    "        error.append(names[df.iloc[i-1,0][9:-4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7658e8f2-c8fc-4f55-8f04-a5f24d85b65a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1410"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(suc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2319ff5b-aa21-46b7-96f3-ebbcae2190bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1605"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(relation_dict_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "00936837-a355-4516-89e3-723e0e73889a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b73d21-3d30-4833-af24-b8116f35dc77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505e77f7-748f-462c-b288-d82d47985db0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f84600cb-aac5-4f8c-b10c-e980d5bca393",
   "metadata": {},
   "source": [
    "## Deal with AllenNLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "440aacb0-6152-4027-b099-3dece5eb73d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"..\")\n",
    "PREDICTOR = Predictor.from_path(\"https://storage.googleapis.com/allennlp-public-models/openie-model.2020.03.26.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "271e9675-cdf6-4be5-881f-a56d80936640",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(sent):\n",
    "    return re.sub(' +', ' ', sent.replace('\\r', ' ').replace('\\n', ' '))\n",
    "def get_tags_allen(sent):\n",
    "    sent = sent.replace('[', '(').replace(']', ')')\n",
    "    res = PREDICTOR.predict(\n",
    "      sentence=sent\n",
    "    )\n",
    "    return res\n",
    "def parse_allen(ss):\n",
    "    words = ss['words']\n",
    "    res = []\n",
    "    for v in ss['verbs']:\n",
    "        tags = v['tags']\n",
    "        d = {}\n",
    "        for i in range(len(words)):\n",
    "            t = tags[i].replace('I-', '').replace('B-', '')\n",
    "            w = words[i]\n",
    "            if t in d:\n",
    "                d[t] += ' '+ w\n",
    "            else:\n",
    "                d[t] = w\n",
    "        res.append(d)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e23ccc86-3ee3-4a16-afd9-0514c0425ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence2allennlp={}\n",
    "for i in relation_dict_copy.keys():\n",
    "    res=get_tags_allen(i)\n",
    "    ress=parse_allen(res)\n",
    "    sentence2allennlp[i]=ress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2175b34e-7f25-483b-9908-95cdbd551342",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,j in relation_dict_copy.items():\n",
    "    for k in j:\n",
    "        k1=k.get('target1').translate(str.maketrans({\"-\":  r\"\\-\",\"\\\\\": r\"\\\\\", \"^\":  r\"\\^\",\"$\":  r\"\\$\",\"*\":  r\"\\*\",\".\":  r\"\\.\",\"(\":  r\"\\(\",\")\":  r\"\\)\",\"+\":  r\"\\+\",\"[\":  r\"\\[\",\"]\":  r\"\\]\",\n",
    "                  \"{\":  r\"\\{\",\"}\":  r\"\\}\",\"|\":  r\"\\|\",\"?\":  r\"\\?\"}))\n",
    "        k2=k.get('target2').translate(str.maketrans({\"-\":  r\"\\-\",\"\\\\\": r\"\\\\\", \"^\":  r\"\\^\",\"$\":  r\"\\$\",\"*\":  r\"\\*\",\".\":  r\"\\.\",\"(\":  r\"\\(\",\")\":  r\"\\)\",\"+\":  r\"\\+\",\"[\":  r\"\\[\",\"]\":  r\"\\]\",\n",
    "                  \"{\":  r\"\\{\",\"}\":  r\"\\}\",\"|\":  r\"\\|\",\"?\":  r\"\\?\"}))\n",
    "        for l in sentence2allennlp.get(i):\n",
    "            if l.get('ARG1') and l.get('ARG2') and l.get('V'):\n",
    "                if re.search(k1,l.get('ARG1')) and re.search(k2,l.get('ARG2')):\n",
    "                    k['allennlp']=k.get('allennlp',[])+[[k.get('target1'), l.get('V') ,k.get('target2')]]\n",
    "                elif re.search(k2,l.get('ARG1')) and re.search(k1,l.get('ARG2')):\n",
    "                    k['allennlp']=k.get('allennlp',[])+[[k.get('target2'), l.get('V') ,k.get('target1')]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2c72e5b2-6b41-4e2f-a77f-d8f2cc7fb050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'PMID': '36915137', 'entity1': 'ACAN', 'entity2': 'MIR34A', 'sentence': 'Furthermore, results from western blot demonstrated that metformin suppressed expression of senescence-associated protein P16, proinflammatory cytokine IL-6 and catabolic gene MMP-13 while elevated expression of anabolic proteins such as Collagen type II and Aggrecan, which could be attenuated by transfection with miR-34a mimics.', 'AB': 'BACKGROUND: Osteoarthritis (OA) is the most common degenerative disease in joints among elderly patients. Senescence is deeply involved in the pathogenesis of osteoarthritis. Metformin is widely used as the first-line drug for Type 2 diabetes mellitus (T2DM), and has great potential for the treatment of other aging-related disorders, including OA. However, the role of metformin in OA is not fully elucidated. Therefore, our aim here was to investigate the effects of metformin on human chondrocytes. METHODS: After metformin treatment, expression level of microRNA-34a and SIRT1 in chondrocyte were detected with quantitative real-time PCR and immunofluorescence staining. Then, microRNA-34a mimic and small interfering RNA (siRNA) against SIRT1 (siRNA-SIRT1) were transfected into chondrocyte. Senescence-associated beta-galactosidase (SA-beta-gal) staining was performed to assess chondrocyte senescence. Chondrocyte viability was illustrated with MTT and colony formation assays. Western blot was conducted to detect the expression of P16, IL-6, matrix metalloproteinase-13 (MMP-13), Collagen type II (COL2A1) and Aggrecan (ACAN). RESULTS: We found that metformin treatment (1 mM) inhibited microRNA-34a while promoted SIRT1 expression in OA chondrocytes. Both miR-34a mimics and siRNA against SIRT1 inhibited SIRT1 expression in chondrocytes. SA-beta-gal staining assay confirmed that metformin reduced SA-beta-gal-positive rate of chondrocytes, while transfection with miR-34a mimics or siRNA-SIRT1 reversed it. MTT assay and colony formation assay showed that metformin accelerated chondrocyte proliferation, while miR-34a mimics or siRNA-SIRT1 weakened this effect. Furthermore, results from western blot demonstrated that metformin suppressed expression of senescence-associated protein P16, proinflammatory cytokine IL-6 and catabolic gene MMP-13 while elevated expression of anabolic proteins such as Collagen type II and Aggrecan, which could be attenuated by transfection with miR-34a mimics. CONCLUSION: Overall, our data suggest that metformin regulates chondrocyte senescence and proliferation through microRNA-34a/SIRT1 pathway, indicating it could be a novel strategy for OA treatment.', 'target1': 'Aggrecan', 'target1_type': 'Gene', 'target2': 'miR-34a', 'target2_type': 'RNA', 'allennlp': [['Aggrecan', 'be', 'miR-34a']]}\n"
     ]
    }
   ],
   "source": [
    "for i,j in relation_dict_copy.items():\n",
    "    for k in j:\n",
    "        if k.get('allennlp'):\n",
    "            print(k)\n",
    "            break\n",
    "    else:\n",
    "        continue\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a70db993-e2b3-4120-9190-5745fbf99501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1605"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentence2adv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "dfb7f62f-02bb-4eec-83bd-6f4897089c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "negativewords=['no','not','never','hardly','barely','scarcely','rarely','few','little','seldom','neither','nor']\n",
    "negativewords_dict={}\n",
    "for i in negativewords:\n",
    "    negativewords_dict[i]=i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4accfd64-869b-43c2-b86e-0424190d5ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parent process 96137.\n",
      "Waiting for all subprocesses done...\n",
      "All subprocesses done.\n",
      "The running time is 14s\n"
     ]
    }
   ],
   "source": [
    "def work(i,j,triple,abnormal, negative_sentences,networkx_raw):\n",
    "    adv=sentence2adv.get(i)\n",
    "    words=sentence2words.get(i)\n",
    "    sentence=i\n",
    "    relations=sentence2relations.get(i)\n",
    "    relations_display=[relation[-2] for relation in relations]\n",
    "    verblist=sentence2verblist.get(i)\n",
    "    verbprototype=sentence2verbprototype.get(i)\n",
    "    verbprototype_dict={}\n",
    "    for verbp in verbprototype:\n",
    "        verbprototype_dict.update(verbp)\n",
    "    G = nx.Graph()\n",
    "    for word in words:\n",
    "        G.add_node(word)\n",
    "    G.add_node('root')\n",
    "    for r in range(len(relations)):\n",
    "        if relations[r][4]=='root':\n",
    "            G.add_edge(relations[r][0], 'root',labels=relations[r][4])\n",
    "        else:\n",
    "            G.add_edge(relations[r][0], relations[r][1],labels=relations[r][4])\n",
    "    for k in j:\n",
    "        if verblist:\n",
    "            k1=k.get('target1').translate(str.maketrans({\"-\":  r\"\\-\",\"\\\\\": r\"\\\\\", \"^\":  r\"\\^\",\"$\":  r\"\\$\",\"*\":  r\"\\*\",\".\":  r\"\\.\",\"(\":  r\"\\(\",\")\":  r\"\\)\",\"+\":  r\"\\+\",\"[\":  r\"\\[\",\"]\":  r\"\\]\",\n",
    "                                      \"{\":  r\"\\{\",\"}\":  r\"\\}\",\"|\":  r\"\\|\",\"?\":  r\"\\?\"}))\n",
    "            k2=k.get('target2').translate(str.maketrans({\"-\":  r\"\\-\",\"\\\\\": r\"\\\\\", \"^\":  r\"\\^\",\"$\":  r\"\\$\",\"*\":  r\"\\*\",\".\":  r\"\\.\",\"(\":  r\"\\(\",\")\":  r\"\\)\",\"+\":  r\"\\+\",\"[\":  r\"\\[\",\"]\":  r\"\\]\",\n",
    "                                      \"{\":  r\"\\{\",\"}\":  r\"\\}\",\"|\":  r\"\\|\",\"?\":  r\"\\?\"}))\n",
    "            if re.search(k1,sentence) and re.search(k2,sentence):\n",
    "                worddict={}\n",
    "                for word in words:\n",
    "                    worddict[word]=word\n",
    "                if re.search(k1,sentence).span()[0] < re.search(k2,sentence).span()[0]:\n",
    "                    k1_word=k.get('target1')\n",
    "                    k2_word=k.get('target2')\n",
    "                    if not worddict.get(k1_word):\n",
    "                        for word in words:\n",
    "                            if re.search(r'-',word) and re.search(k1,word):\n",
    "                                k1_word=word\n",
    "                    if not worddict.get(k2_word):\n",
    "                        for word in words:\n",
    "                            if re.search(r'-',word) and re.search(k2,word):\n",
    "                                k2_word=word\n",
    "                    try:\n",
    "                        path=nx.shortest_path(G, source=re.split('[ -]',k1_word)[-1], target=re.split('[ -]',k2_word)[-1])\n",
    "                    except:\n",
    "                        abnormal.append(i)\n",
    "                    else:\n",
    "                        verbdict={}\n",
    "                        for verb in verblist:\n",
    "                            verbdict.update(verb)\n",
    "                        verbrelation=''\n",
    "                        for one in path:\n",
    "                            if verbdict.get(one):\n",
    "                                verbrelation=one \n",
    "                        if verbrelation :\n",
    "                            negative=False\n",
    "                            for index_passive,passive in enumerate(relations_display):\n",
    "                                if passive=='aux:pass':\n",
    "                                    if relations[index_passive][1]==verbrelation:\n",
    "                                        verb_prototype=verbrelation\n",
    "                                        break\n",
    "                                elif passive=='acl' and relations[index_passive][-1]=='VBN':\n",
    "                                    if relations[index_passive][0]==verbrelation:\n",
    "                                        verb_prototype=verbrelation\n",
    "                                        break\n",
    "                            else:\n",
    "                                for v in verbprototype:\n",
    "                                    if v.get(verbrelation):\n",
    "                                        verb_prototype=v.get(verbrelation)\n",
    "                                        break\n",
    "                            if verb_prototype:\n",
    "                                for relation in relations:\n",
    "                                    if relation[1]==verbrelation and negativewords_dict.get(relation[0]):\n",
    "                                        negative=True\n",
    "                                if not negative:\n",
    "                                    triple.append({'triple':[k.get('target1'),verb_prototype,k.get('target2')],\\\n",
    "                                                        'PMID':k.get('PMID'), 'sentence':sentence,'AB':k.get('AB'),\n",
    "                                                   'former_target':k.get('target1'),'former_entity':k.get('entity1'),'former_entity_type':k.get('target1_type'),\n",
    "                                                   'verb':verbrelation,'verbprototype':verbprototype_dict.get(verbrelation),'latter_target':k.get('target2'),\n",
    "                                                   'latter_entity':k.get('entity2'),'latter_entity_type':k.get('target2_type')})\n",
    "                                    k['networkx']=[k.get('target1'),verb_prototype,k.get('target2')]\n",
    "                                else:\n",
    "                                    negative_sentences.append(i)\n",
    "                else:\n",
    "                    k1_word=k.get('target1')\n",
    "                    k2_word=k.get('target2')\n",
    "                    if not worddict.get(k1_word):\n",
    "                        for word in words:\n",
    "                            if re.search(r'-',word) and re.search(k1,word):\n",
    "                                k1_word=word\n",
    "                    if not worddict.get(k2_word):\n",
    "                        for word in words:\n",
    "                            if re.search(r'-',word) and re.search(k2,word):\n",
    "                                k2_word=word\n",
    "                    try:\n",
    "                        path=nx.shortest_path(G, source=re.split('[ -]',k2_word)[-1], target=re.split('[ -]',k1_word)[-1])\n",
    "                    except:\n",
    "                        abnormal.append(i)\n",
    "                    else:\n",
    "                        verbdict={}\n",
    "                        for verb in verblist:\n",
    "                            verbdict.update(verb)\n",
    "                        verbrelation=''\n",
    "                        for one in path:\n",
    "                            if verbdict.get(one):\n",
    "                                verbrelation=one\n",
    "                        if verbrelation:\n",
    "                            negative=False\n",
    "                            for index_passive,passive in enumerate(relations_display):\n",
    "                                if passive=='aux:pass':\n",
    "                                    if relations[index_passive][1]==verbrelation:\n",
    "                                        verb_prototype=verbrelation\n",
    "                                        break\n",
    "                                elif passive=='acl' and relations[index_passive][-1]=='VBN':\n",
    "                                    if relations[index_passive][0]==verbrelation:\n",
    "                                        verb_prototype=verbrelation\n",
    "                                        break\n",
    "                            else:\n",
    "                                for v in verbprototype:\n",
    "                                    if v.get(verbrelation):\n",
    "                                        verb_prototype=v.get(verbrelation)\n",
    "                                        break\n",
    "                            if verb_prototype:\n",
    "                                for relation in relations:\n",
    "                                    if relation[1]==verbrelation and negativewords_dict.get(relation[0]):\n",
    "                                        negative=True\n",
    "                                if not negative:\n",
    "                                    triple.append({'triple':[k.get('target2'),verb_prototype,k.get('target1')],\\\n",
    "                                                        'PMID':k.get('PMID'), 'sentence':sentence,'AB':k.get('AB'),\n",
    "                                                   'former_target':k.get('target2'),'former_entity':k.get('entity2'),'former_entity_type':k.get('target2_type'),\n",
    "                                                   'verb':verbrelation,'verbprototype':verbprototype_dict.get(verbrelation),'latter_target':k.get('target1'),\n",
    "                                                   'latter_entity':k.get('entity1'),'latter_entity_type':k.get('target1_type')})\n",
    "                                    k['networkx']=[k.get('target2'),verb_prototype,k.get('target1')]\n",
    "                                else:\n",
    "                                    negative_sentences.append(i)\n",
    "        networkx_raw.append(k)\n",
    "if __name__=='__main__':\n",
    "    start=datetime.datetime.now()\n",
    "    print('Parent process %s.' % os.getpid())\n",
    "    p=Pool(40)\n",
    "    manager=Manager()\n",
    "    triple=manager.list()\n",
    "    abnormal=manager.list()\n",
    "    negative_sentences=manager.list()\n",
    "    networkx_raw=manager.list()\n",
    "    for i,j in relation_dict_copy.items():\n",
    "        p.apply_async(work, args=(i,j,triple,abnormal,negative_sentences,networkx_raw))\n",
    "    print('Waiting for all subprocesses done...')\n",
    "    p.close()\n",
    "    p.join()\n",
    "    print('All subprocesses done.')\n",
    "    end=datetime.datetime.now()\n",
    "    print(\"The running time is \"+str((end-start).seconds)+\"s\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6e3344e8-91eb-464e-a2ad-57e1ac974ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "triple_list=list(triple)\n",
    "abnormal_list=list(abnormal)\n",
    "negative_list=list(negative_sentences)\n",
    "networkx_raw_list=list(networkx_raw)\n",
    "networkx_raw_dict={}\n",
    "for i in networkx_raw_list:\n",
    "    networkx_raw_dict[i.get('sentence')]=networkx_raw_dict.get(i.get('sentence'),[])+[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d5cc028f-1b4a-4bf5-90dd-af404b0b9799",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(triple_list,open('results/step3/triple_list.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "de2953f3-bf0d-46a0-80d6-e70cb4ff72af",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(abnormal_list,open('results/step3/abnormal_list.pkl','wb'))\n",
    "pickle.dump(negative_list,open('results/step3/negative_list.pkl','wb'))\n",
    "pickle.dump(networkx_raw_list,open('results/step3/networkx_raw_list.pkl','wb'))\n",
    "pickle.dump(networkx_raw_dict,open('results/step3/networkx_raw_dict.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0b52906b-0e18-4a24-a1cb-51fa734d495e",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_pick_pubtator=pickle.load(open('results/step1/raw_pick_pubtator.pkl','rb'))\n",
    "rawpickwithAB={}\n",
    "for i in raw_pick_pubtator:\n",
    "    rawpickwithAB[i.get('PMID')]=i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ba92d711-8208-42ae-8a84-dc64e122c442",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PMID': '36915137',\n",
       " 'entity1': 'ACAN',\n",
       " 'entity2': 'CDKN2A',\n",
       " 'sentence': 'Furthermore, results from western blot demonstrated that metformin suppressed expression of senescence-associated protein P16, proinflammatory cytokine IL-6 and catabolic gene MMP-13 while elevated expression of anabolic proteins such as Collagen type II and Aggrecan, which could be attenuated by transfection with miR-34a mimics.',\n",
       " 'AB': 'BACKGROUND: Osteoarthritis (OA) is the most common degenerative disease in joints among elderly patients. Senescence is deeply involved in the pathogenesis of osteoarthritis. Metformin is widely used as the first-line drug for Type 2 diabetes mellitus (T2DM), and has great potential for the treatment of other aging-related disorders, including OA. However, the role of metformin in OA is not fully elucidated. Therefore, our aim here was to investigate the effects of metformin on human chondrocytes. METHODS: After metformin treatment, expression level of microRNA-34a and SIRT1 in chondrocyte were detected with quantitative real-time PCR and immunofluorescence staining. Then, microRNA-34a mimic and small interfering RNA (siRNA) against SIRT1 (siRNA-SIRT1) were transfected into chondrocyte. Senescence-associated beta-galactosidase (SA-beta-gal) staining was performed to assess chondrocyte senescence. Chondrocyte viability was illustrated with MTT and colony formation assays. Western blot was conducted to detect the expression of P16, IL-6, matrix metalloproteinase-13 (MMP-13), Collagen type II (COL2A1) and Aggrecan (ACAN). RESULTS: We found that metformin treatment (1 mM) inhibited microRNA-34a while promoted SIRT1 expression in OA chondrocytes. Both miR-34a mimics and siRNA against SIRT1 inhibited SIRT1 expression in chondrocytes. SA-beta-gal staining assay confirmed that metformin reduced SA-beta-gal-positive rate of chondrocytes, while transfection with miR-34a mimics or siRNA-SIRT1 reversed it. MTT assay and colony formation assay showed that metformin accelerated chondrocyte proliferation, while miR-34a mimics or siRNA-SIRT1 weakened this effect. Furthermore, results from western blot demonstrated that metformin suppressed expression of senescence-associated protein P16, proinflammatory cytokine IL-6 and catabolic gene MMP-13 while elevated expression of anabolic proteins such as Collagen type II and Aggrecan, which could be attenuated by transfection with miR-34a mimics. CONCLUSION: Overall, our data suggest that metformin regulates chondrocyte senescence and proliferation through microRNA-34a/SIRT1 pathway, indicating it could be a novel strategy for OA treatment.',\n",
       " 'target1': 'Aggrecan',\n",
       " 'target1_type': 'Gene',\n",
       " 'target2': 'P16',\n",
       " 'target2_type': 'Gene'}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "networkx_raw_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1cd05c1a-8899-4a8e-9ae3-8c627b78f992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1605"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(networkx_raw_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6b378fed-619d-4988-9cb0-9676ff487162",
   "metadata": {},
   "outputs": [],
   "source": [
    "be=['be','am','is','are','was','were','have been','has been']\n",
    "bedict={}\n",
    "for i in be:\n",
    "    bedict[i]=i\n",
    "can=['can','could','will','would','may','might']\n",
    "candict={}\n",
    "for i in can:\n",
    "    candict[i]=i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "aa802227-0c1a-41a2-849d-33364e90ef5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in networkx_raw_list:\n",
    "    openie_mid=[]\n",
    "    openie_final=[]\n",
    "    if i.get('openie'):\n",
    "        for j in i.get('openie'):\n",
    "            if not bedict.get(j[1]) and not candict.get(j[1]):\n",
    "                openie_mid.append(j)\n",
    "        adv=sentence2adv.get(i.get('sentence_transformed'))\n",
    "        adv_dict={}\n",
    "        for l in adv:\n",
    "            adv_dict.update(l)\n",
    "        for k in openie_mid:\n",
    "            for m in k[1].split(' '):\n",
    "                if adv_dict.get(m):\n",
    "                    break\n",
    "            else:\n",
    "                if k not in openie_final:\n",
    "                    openie_final.append(k)\n",
    "    i['openie_final']=openie_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bad4ea4c-d355-4173-8cdd-3e72b2b48989",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in networkx_raw_list:\n",
    "    allennlp_final=[]\n",
    "    if i.get('allennlp'):\n",
    "        for j in i.get('allennlp'):\n",
    "            if not bedict.get(j[1]) and not candict.get(j[1]):\n",
    "                allennlp_final.append(j)\n",
    "    i['allennlp_final']=allennlp_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "74cc04fe-cb9f-45b8-8655-900b80a8794d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in networkx_raw_list:\n",
    "    if i.get('networkx'):\n",
    "        if bedict.get(i.get('networkx')[1]):\n",
    "            i['networkx']=''\n",
    "        elif i.get('networkx')[1]=='\"':\n",
    "            i['networkx']=''\n",
    "    else:\n",
    "        i['networkx']=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3b70e380-ca99-4aeb-b749-49ee188b8749",
   "metadata": {},
   "outputs": [],
   "source": [
    "networkx_raw_final=[]\n",
    "for i in networkx_raw_list:\n",
    "    if i.get('networkx') or i.get('openie_final') or i.get('allennlp_final'):\n",
    "        networkx_raw_final.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bcfe38dc-1487-436b-a75b-b4c74a44e7e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "919"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(networkx_raw_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "bf155ffe-8edf-4681-93f9-4f87191e26f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in networkx_raw_final:\n",
    "    bidirection=False\n",
    "    if i.get('networkx'):\n",
    "        if i.get('networkx')[1]=='associated' or i.get('networkx')[1]=='associate' :\n",
    "            i['bidirection']=True\n",
    "            continue\n",
    "    if i.get('allennlp'):\n",
    "        for j in i.get('openie_final'):\n",
    "            if j=='associated' or j=='associate' :\n",
    "                bidirection=True\n",
    "                break\n",
    "    if i.get('openie_final'):\n",
    "        for j in i.get('openie_final'):\n",
    "            for k in j[1].split(' '):\n",
    "                if k=='associated' or  k=='associate' :\n",
    "                    bidirection=True\n",
    "                    break\n",
    "            else:\n",
    "                continue\n",
    "            break\n",
    "    i['bidirection']=bidirection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "abd25f1f-9107-4d20-8aca-edc1209d3a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "Relation_raw=copy.deepcopy(networkx_raw_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e7148b0c-6e9b-438e-ae0f-4f46f70bdc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(networkx_raw_final,open('results/step3/networkx_raw_final.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0a1e33d8-fb62-4a4c-81fa-8e9d32526989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PMID': '36991516',\n",
       " 'entity1': 'PGR',\n",
       " 'entity2': 'Neoplasms',\n",
       " 'sentence': 'Consistent with the subtype association, tumor DNAm AA was positively correlated with ESR1 (Pearson r = 0.39, P = 6.3e-06) and PGR (Pearson r = 0.36, P = 2.4e-05) gene expression.',\n",
       " 'AB': \"BACKGROUND: Few studies have examined epigenetic age acceleration (AA), the difference between DNA methylation (DNAm) predicted age and chronological age, in relation to somatic genomic features in paired cancer and normal tissue, with less work done in non-European populations. In this study, we aimed to examine DNAm age and its associations with breast cancer risk factors, subtypes, somatic genomic profiles including mutation and copy number alterations and other aging markers in breast tissue of Chinese breast cancer (BC) patients from Hong Kong. METHODS: We performed genome-wide DNA methylation profiling of 196 tumor and 188 paired adjacent normal tissue collected from Chinese BC patients in Hong Kong (HKBC) using Illumina MethylationEPIC array. The DNAm age was calculated using Horvath's pan-tissue clock model. Somatic genomic features were based on data from RNA sequencing (RNASeq), whole-exome sequencing (WES), and whole-genome sequencing (WGS). Pearson's correlation (r), Kruskal-Wallis test, and regression models were used to estimate associations of DNAm AA with somatic features and breast cancer risk factors. RESULTS: DNAm age showed a stronger correlation with chronological age in normal (Pearson r = 0.78, P < 2.2e-16) than in tumor tissue (Pearson r = 0.31, P = 7.8e-06). Although overall DNAm age or AA did not vary significantly by tissue within the same individual, luminal A tumors exhibited increased DNAm AA (P = 0.004) while HER2-enriched/basal-like tumors exhibited markedly lower DNAm AA (P = < .0001) compared with paired normal tissue. Consistent with the subtype association, tumor DNAm AA was positively correlated with ESR1 (Pearson r = 0.39, P = 6.3e-06) and PGR (Pearson r = 0.36, P = 2.4e-05) gene expression. In line with this, we found that increasing DNAm AA was associated with higher body mass index (P = 0.039) and earlier age at menarche (P = 0.035), factors that are related to cumulative exposure to estrogen. In contrast, variables indicating extensive genomic instability, such as TP53 somatic mutations, high tumor mutation/copy number alteration burden, and homologous repair deficiency were associated with lower DNAm AA. CONCLUSIONS: Our findings provide additional insights into the complexity of breast tissue aging that is associated with the interaction of hormonal, genomic, and epigenetic mechanisms in an East Asian population.\",\n",
       " 'target1': 'PGR',\n",
       " 'target1_type': 'Gene',\n",
       " 'target2': 'tumor',\n",
       " 'target2_type': 'Disease',\n",
       " 'allennlp': [['tumor', 'was', 'PGR']],\n",
       " 'networkx': ['tumor', 'correlated', 'PGR'],\n",
       " 'openie_final': [],\n",
       " 'allennlp_final': [],\n",
       " 'bidirection': False}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "networkx_raw_final[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fb582c18-111a-4960-8f1b-598c679e1d85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "919"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(networkx_raw_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1f9f4e4f-6656-4bfe-85b5-ec8f9d99adf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PMID': '36991516',\n",
       " 'entity1': 'PGR',\n",
       " 'entity2': 'Neoplasms',\n",
       " 'sentence': 'Consistent with the subtype association, tumor DNAm AA was positively correlated with ESR1 (Pearson r = 0.39, P = 6.3e-06) and PGR (Pearson r = 0.36, P = 2.4e-05) gene expression.',\n",
       " 'AB': \"BACKGROUND: Few studies have examined epigenetic age acceleration (AA), the difference between DNA methylation (DNAm) predicted age and chronological age, in relation to somatic genomic features in paired cancer and normal tissue, with less work done in non-European populations. In this study, we aimed to examine DNAm age and its associations with breast cancer risk factors, subtypes, somatic genomic profiles including mutation and copy number alterations and other aging markers in breast tissue of Chinese breast cancer (BC) patients from Hong Kong. METHODS: We performed genome-wide DNA methylation profiling of 196 tumor and 188 paired adjacent normal tissue collected from Chinese BC patients in Hong Kong (HKBC) using Illumina MethylationEPIC array. The DNAm age was calculated using Horvath's pan-tissue clock model. Somatic genomic features were based on data from RNA sequencing (RNASeq), whole-exome sequencing (WES), and whole-genome sequencing (WGS). Pearson's correlation (r), Kruskal-Wallis test, and regression models were used to estimate associations of DNAm AA with somatic features and breast cancer risk factors. RESULTS: DNAm age showed a stronger correlation with chronological age in normal (Pearson r = 0.78, P < 2.2e-16) than in tumor tissue (Pearson r = 0.31, P = 7.8e-06). Although overall DNAm age or AA did not vary significantly by tissue within the same individual, luminal A tumors exhibited increased DNAm AA (P = 0.004) while HER2-enriched/basal-like tumors exhibited markedly lower DNAm AA (P = < .0001) compared with paired normal tissue. Consistent with the subtype association, tumor DNAm AA was positively correlated with ESR1 (Pearson r = 0.39, P = 6.3e-06) and PGR (Pearson r = 0.36, P = 2.4e-05) gene expression. In line with this, we found that increasing DNAm AA was associated with higher body mass index (P = 0.039) and earlier age at menarche (P = 0.035), factors that are related to cumulative exposure to estrogen. In contrast, variables indicating extensive genomic instability, such as TP53 somatic mutations, high tumor mutation/copy number alteration burden, and homologous repair deficiency were associated with lower DNAm AA. CONCLUSIONS: Our findings provide additional insights into the complexity of breast tissue aging that is associated with the interaction of hormonal, genomic, and epigenetic mechanisms in an East Asian population.\",\n",
       " 'target1': 'PGR',\n",
       " 'target1_type': 'Gene',\n",
       " 'target2': 'tumor',\n",
       " 'target2_type': 'Disease',\n",
       " 'allennlp': [['tumor', 'was', 'PGR']],\n",
       " 'networkx': ['tumor', 'correlated', 'PGR'],\n",
       " 'openie_final': [],\n",
       " 'allennlp_final': [],\n",
       " 'bidirection': False}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "networkx_raw_final[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3cd9ecd0-b2d2-44c9-b3ca-1f3237152446",
   "metadata": {},
   "outputs": [],
   "source": [
    "collections_Relation_raw=db.Relation_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e9168283-f0a4-4698-84d3-623753835610",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2023_05_09'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "now_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "66c2ba7d-2914-46da-9b1f-985516f3aee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in Relation_raw:\n",
    "    i['addtime']=now_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6a24efb6-72fd-4954-907a-aef6ec62e09b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertManyResult at 0x7ff616506c80>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collections_Relation_raw.insert_many(Relation_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fcc9b6-6f87-4002-a235-94c572fe69aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6657dd-e3e4-4a65-b0a9-2e6a0d83c13b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e50321c8-e689-42cb-add9-8ac33c743cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Relation_raw_all_with_disease=copy.deepcopy(Relation_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "610a8457-beb3-4a73-8831-c10bcdec59c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "919"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Relation_raw_all_with_disease)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4a9e5856-7ccd-447d-ac1d-38cf0290e791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PMID': '36905877',\n",
       " 'entity1': 'FLT4',\n",
       " 'entity2': 'Alzheimer Disease',\n",
       " 'sentence': 'Previous work in postmortem human dorsolateral prefrontal cortex demonstrated that higher transcript levels of VEGFB, PGF, FLT1, and FLT4 are associated with AD dementia, worse cognitive outcomes, and higher AD neuropathology.',\n",
       " 'AB': \"The vascular endothelial growth factor (VEGF) signaling family has been implicated in neuroprotection and clinical progression in Alzheimer's disease (AD). Previous work in postmortem human dorsolateral prefrontal cortex demonstrated that higher transcript levels of VEGFB, PGF, FLT1, and FLT4 are associated with AD dementia, worse cognitive outcomes, and higher AD neuropathology. To expand prior work, we leveraged bulk RNA sequencing data, single nucleus RNA (snRNA) sequencing, and both tandem mass tag and selected reaction monitoring mass spectrometry proteomic measures from the post-mortem brain. Outcomes included AD diagnosis, cognition, and AD neuropathology. We replicated previously reported VEGFB and FLT1 results, whereby higher expression was associated with worse outcomes, and snRNA results suggest microglia, oligodendrocytes, and endothelia may play a central role in these associations. Additionally, FLT4 and NRP2 expression were associated with better cognitive outcomes. This study provides a comprehensive molecular picture of the VEGF signaling family in cognitive aging and AD and critical insight towards the biomarker and therapeutic potential of VEGF family members in AD.\",\n",
       " 'target1': 'FLT4',\n",
       " 'target1_type': 'Gene',\n",
       " 'target2': 'AD dementia',\n",
       " 'target2_type': 'Disease',\n",
       " 'allennlp': [['FLT4', 'associated', 'AD dementia']],\n",
       " 'openie_final': [],\n",
       " 'allennlp_final': [['FLT4', 'associated', 'AD dementia']],\n",
       " 'networkx': '',\n",
       " 'bidirection': False,\n",
       " 'addtime': '2023_05_09',\n",
       " '_id': ObjectId('645b4480f73d69a91714a409')}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Relation_raw_all_with_disease[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2d9ac433-5003-42d6-92c4-94fb68b39096",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_es=json.load(open('results/step2/all_es_lack.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "16c8ffeb-aae6-43e4-b08c-ef868c8b7148",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_chemical_type2={}\n",
    "for i in all_es:\n",
    "    if not multi_chemical_type2.get(i.get('entity')):\n",
    "        multi_chemical_type2[i.get('entity')]=[i.get('type')]\n",
    "    else:\n",
    "        if i.get('type') not in multi_chemical_type2.get(i.get('entity')):\n",
    "            multi_chemical_type2[i.get('entity')]+=[i.get('type')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "162511e2-2851-49f1-aefa-4d951198f483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Lipopolysaccharides': ['Carbohydrate', 'Lipid', 'Toxin']}\n",
      "{'Vancomycin': ['Carbohydrate', 'Peptide']}\n",
      "{'Ceramides': ['Carbohydrate', 'Lipid']}\n",
      "{'Sphingomyelins': ['Carbohydrate', 'Lipid']}\n",
      "{'Bleomycin': ['Carbohydrate', 'Peptide']}\n",
      "{'Teicoplanin': ['Carbohydrate', 'Peptide']}\n",
      "{'Lipid A': ['Carbohydrate', 'Lipid', 'Toxin']}\n",
      "{'G(M1) Ganglioside': ['Carbohydrate', 'Lipid']}\n",
      "{'Gangliosides': ['Carbohydrate', 'Lipid']}\n",
      "{'Glycosphingolipids': ['Carbohydrate', 'Lipid']}\n",
      "{'Sulfoglycosphingolipids': ['Carbohydrate', 'Lipid']}\n",
      "{'Glycolipids': ['Carbohydrate', 'Lipid']}\n",
      "{'G(M3) Ganglioside': ['Carbohydrate', 'Lipid']}\n",
      "{'Glycopeptides': ['Carbohydrate', 'Peptide']}\n",
      "{'Glycosylphosphatidylinositols': ['Carbohydrate', 'Lipid']}\n",
      "{'Globosides': ['Carbohydrate', 'Lipid']}\n",
      "{'Ristocetin': ['Carbohydrate', 'Peptide']}\n",
      "{'Glucosylceramides': ['Carbohydrate', 'Lipid']}\n",
      "{'Holothurin': ['Carbohydrate', 'Toxin']}\n",
      "{'Glycerylphosphorylcholine': ['Carbohydrate', 'Lipid']}\n",
      "{'Glycerophosphates': ['Carbohydrate', 'Lipid']}\n",
      "{'Cerebrosides': ['Carbohydrate', 'Lipid']}\n",
      "{'Psychosine': ['Carbohydrate', 'Lipid']}\n",
      "{'Lactosylceramides': ['Carbohydrate', 'Lipid']}\n",
      "{'Phospholipid Ethers': ['Carbohydrate', 'Lipid']}\n",
      "{'Galactolipids': ['Carbohydrate', 'Lipid']}\n",
      "{'O Antigens': ['Carbohydrate', 'Lipid', 'Toxin']}\n",
      "{'Daptomycin': ['Lipid', 'Peptide']}\n",
      "{'Caspofungin': ['Lipid', 'Peptide']}\n",
      "{'Micafungin': ['Lipid', 'Peptide']}\n",
      "{'Lipopeptides': ['Lipid', 'Peptide']}\n",
      "{'Cilastatin, Imipenem Drug Combination': ['Lipid', 'Pharmaceutical Preparations']}\n",
      "{'Polymyxin B': ['Lipid', 'Peptide', 'Protein']}\n",
      "{'Exenatide': ['Peptide', 'Toxin']}\n",
      "{'Certolizumab Pegol': ['Peptide', 'Protein']}\n",
      "{'Phalloidine': ['Peptide', 'Toxin']}\n",
      "{'Abciximab': ['Peptide', 'Protein']}\n",
      "{'Alpha-Amanitin': ['Peptide', 'Toxin']}\n",
      "{'Charybdotoxin': ['Peptide', 'Toxin']}\n",
      "{'Angiotensins': ['Peptide', 'Protein']}\n",
      "{'Fas Ligand Protein': ['Peptide', 'Protein']}\n",
      "{'Arginine Vasopressin': ['Peptide', 'Protein']}\n",
      "{'Angiotensin II': ['Peptide', 'Protein']}\n",
      "43\n"
     ]
    }
   ],
   "source": [
    "cxz=0\n",
    "for i,j in multi_chemical_type2.items():\n",
    "    if len(j)>1:\n",
    "        cxz+=1\n",
    "        print({i:j})\n",
    "print(cxz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6d5d8a2a-9150-462d-b4a6-5b737ca91171",
   "metadata": {},
   "outputs": [],
   "source": [
    "Relation_raw_all_final=[]\n",
    "for i in Relation_raw_all_with_disease:\n",
    "    if multi_chemical_type2.get(i.get('entity1')) and multi_chemical_type2.get(i.get('entity2')):\n",
    "        for j in multi_chemical_type2.get(i.get('entity1')):\n",
    "            for k in multi_chemical_type2.get(i.get('entity2')):\n",
    "                mid=copy.deepcopy(i)\n",
    "                mid.update({'target1_type':j,'target2_type':k})\n",
    "                Relation_raw_all_final.append(mid)\n",
    "    else:\n",
    "        Relation_raw_all_final.append(i)\n",
    "        if multi_chemical_type2.get(i.get('entity1')):\n",
    "            for j in multi_chemical_type2.get(i.get('entity1')):\n",
    "                if i.get('target1_type') != j:\n",
    "                    mid=copy.deepcopy(i)\n",
    "                    mid.update({'target1_type':j})\n",
    "                    Relation_raw_all_final.append(mid)\n",
    "        elif multi_chemical_type2.get(i.get('entity2')):\n",
    "            for j in multi_chemical_type2.get(i.get('entity2')):\n",
    "                if i.get('target2_type') != j:\n",
    "                    mid=copy.deepcopy(i)\n",
    "                    mid.update({'target2_type':j})\n",
    "                    Relation_raw_all_final.append(mid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7b98085f-ab87-4de8-b38d-c6bca56c6c6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "925"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Relation_raw_all_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "dbbdc1cd-3965-40da-b2be-151491d499eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "direction=set()\n",
    "direction_list=[]\n",
    "direction_type=[]\n",
    "for i in Relation_raw_all_final:\n",
    "    if i.get('openie_final'):\n",
    "        if i.get('openie_final')[0][0]!=i.get('target1'):\n",
    "            i['entity2'],i['entity1']=i['entity1'],i['entity2']\n",
    "            i['target2_type'],i['target1_type']=i['target1_type'],i['target2_type']\n",
    "            i['target2'],i['target1']=i['target1'],i['target2']\n",
    "    elif i.get('networkx'):\n",
    "        if i.get('networkx')[0]!= i.get('target1'):\n",
    "            i['entity2'],i['entity1']=i['entity1'],i['entity2']\n",
    "            i['target2_type'],i['target1_type']=i['target1_type'],i['target2_type']\n",
    "            i['target2'],i['target1']=i['target1'],i['target2']\n",
    "    elif i.get('allennlp_final'):\n",
    "        if i.get('allennlp_final')[0][0]!=i.get('target1'):\n",
    "            i['entity2'],i['entity1']=i['entity1'],i['entity2']\n",
    "            i['target2_type'],i['target1_type']=i['target1_type'],i['target2_type']\n",
    "            i['target2'],i['target1']=i['target1'],i['target2']\n",
    "    if i.get('bidirection'):\n",
    "        if (i.get('entity2'),(i.get('entity1'))) not in direction :\n",
    "            direction.add((i.get('entity2'),(i.get('entity1'))))\n",
    "            direction_list.append((i.get('entity2'),(i.get('entity1'))))\n",
    "            direction_type.append((i.get('target2_type'),(i.get('target1_type'))))\n",
    "        if (i.get('entity1'),(i.get('entity2'))) not in direction:\n",
    "            direction.add((i.get('entity1'),(i.get('entity2'))))\n",
    "            direction_list.append((i.get('entity1'),(i.get('entity2'))))\n",
    "            direction_type.append((i.get('target1_type'),(i.get('target2_type'))))\n",
    "    else:\n",
    "        direction.add((i.get('entity1'),(i.get('entity2'))))\n",
    "        direction_list.append((i.get('entity1'),(i.get('entity2'))))\n",
    "        direction_type.append((i.get('target1_type'),(i.get('target2_type'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9e63337c-0157-48e6-b644-c6662bbaacd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PMID': '36905877',\n",
       " 'entity1': 'FLT4',\n",
       " 'entity2': 'Alzheimer Disease',\n",
       " 'sentence': 'Previous work in postmortem human dorsolateral prefrontal cortex demonstrated that higher transcript levels of VEGFB, PGF, FLT1, and FLT4 are associated with AD dementia, worse cognitive outcomes, and higher AD neuropathology.',\n",
       " 'AB': \"The vascular endothelial growth factor (VEGF) signaling family has been implicated in neuroprotection and clinical progression in Alzheimer's disease (AD). Previous work in postmortem human dorsolateral prefrontal cortex demonstrated that higher transcript levels of VEGFB, PGF, FLT1, and FLT4 are associated with AD dementia, worse cognitive outcomes, and higher AD neuropathology. To expand prior work, we leveraged bulk RNA sequencing data, single nucleus RNA (snRNA) sequencing, and both tandem mass tag and selected reaction monitoring mass spectrometry proteomic measures from the post-mortem brain. Outcomes included AD diagnosis, cognition, and AD neuropathology. We replicated previously reported VEGFB and FLT1 results, whereby higher expression was associated with worse outcomes, and snRNA results suggest microglia, oligodendrocytes, and endothelia may play a central role in these associations. Additionally, FLT4 and NRP2 expression were associated with better cognitive outcomes. This study provides a comprehensive molecular picture of the VEGF signaling family in cognitive aging and AD and critical insight towards the biomarker and therapeutic potential of VEGF family members in AD.\",\n",
       " 'target1': 'FLT4',\n",
       " 'target1_type': 'Gene',\n",
       " 'target2': 'AD dementia',\n",
       " 'target2_type': 'Disease',\n",
       " 'allennlp': [['FLT4', 'associated', 'AD dementia']],\n",
       " 'openie_final': [],\n",
       " 'allennlp_final': [['FLT4', 'associated', 'AD dementia']],\n",
       " 'networkx': '',\n",
       " 'bidirection': False,\n",
       " 'addtime': '2023_05_09',\n",
       " '_id': ObjectId('645b4480f73d69a91714a409')}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Relation_raw_all_final[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5ec24314-4d22-459d-bfee-e1e86a273280",
   "metadata": {},
   "outputs": [],
   "source": [
    "rules_pairs=['sentence2adv','sentence2relations','sentence2verblist','sentence2verbprototype','sentence2words']\n",
    "names=locals()\n",
    "for i in rules_pairs:\n",
    "    names[i]={}\n",
    "    for k in ['../2023_05_09/results/step3/rules/files/'+i+str(j)+'.pkl' for j in range(1,6)]:\n",
    "        names[i].update(pickle.load(open(k,'rb')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7a7a3828-4863-4b34-bb7a-0b7e70efa050",
   "metadata": {},
   "outputs": [],
   "source": [
    "Relation_raw_all_final_copy=copy.deepcopy(Relation_raw_all_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425c5831-d565-42d5-b1a4-b3eb3905e1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "be=['be','am','is','are','was','were','have been','has been']\n",
    "bedict={}\n",
    "for i in be:\n",
    "    bedict[i]=i\n",
    "can=['can','could','will','would','may','might']\n",
    "candict={}\n",
    "for i in can:\n",
    "    candict[i]=i\n",
    "countt=0\n",
    "counttt=0\n",
    "fdas=[]\n",
    "for i in Relation_raw_all_final_copy:\n",
    "    del_index=set()\n",
    "    if i.get('sentence_transformed'):\n",
    "        verblist=sentence2verblist.get(i.get('sentence_transformed'))\n",
    "    else:\n",
    "        verblist=sentence2verblist.get(i.get('sentence'))\n",
    "    verbrelation=''\n",
    "    real_verb=''\n",
    "    verbdict={}\n",
    "    for verb in verblist:\n",
    "        verbdict.update(verb)\n",
    "    for indexx,j in enumerate(i.get('openie_final')):\n",
    "        one=j[1]\n",
    "        negative=False\n",
    "        if i.get('sentence_transformed'):\n",
    "            relations=sentence2relations.get(i.get('sentence_transformed'))\n",
    "            verbprototype=sentence2verbprototype.get(i.get('sentence_transformed'))\n",
    "        else:\n",
    "            relations=sentence2relations.get(i.get('sentence'))\n",
    "            verbprototype=sentence2verbprototype.get(i.get('sentence'))\n",
    "        for p in one.split(' '):\n",
    "            for relation in relations:\n",
    "                if relation[1]==p and negativewords_dict.get(relation[0]):\n",
    "                    negative=True\n",
    "            if verbdict.get(p):\n",
    "                verbrelation=p\n",
    "                relations_display=[relation[-2] for relation in relations]\n",
    "                verbprototype_dict={}\n",
    "                for verbp in verbprototype:\n",
    "                    verbprototype_dict.update(verbp)\n",
    "                for index_passive,passive in enumerate(relations_display):\n",
    "                    if passive=='aux:pass':\n",
    "                        if relations[index_passive][1]==verbrelation:\n",
    "                            verb_prototype=verbrelation\n",
    "                            break\n",
    "                    elif passive=='acl' and relations[index_passive][-1]=='VBN':\n",
    "                        if relations[index_passive][0]==verbrelation:\n",
    "                            verb_prototype=verbrelation\n",
    "                            break\n",
    "                else:\n",
    "                    for v in verbprototype:\n",
    "                        if v.get(verbrelation):\n",
    "                            verb_prototype=v.get(verbrelation)\n",
    "                            break\n",
    "                if verb_prototype!=one:\n",
    "                    if countt<10:\n",
    "                        countt+=1\n",
    "                if not negative:\n",
    "                    i['openie_final'][indexx][1]=verb_prototype\n",
    "            elif bedict.get(one):\n",
    "                if i.get('sentence_transformed'):\n",
    "                    relations=sentence2relations.get(i.get('sentence_transformed'))\n",
    "                    verbprototype=sentence2verbprototype.get(i.get('sentence_transformed'))\n",
    "                else:\n",
    "                    relations=sentence2relations.get(i.get('sentence'))\n",
    "                    verbprototype=sentence2verbprototype.get(i.get('sentence'))\n",
    "                for relation in relations:\n",
    "                    if relation[1]==one and negativewords_dict.get(relation[0]):\n",
    "                        negative=True\n",
    "                if not negative:\n",
    "                    i['openie_final'][indexx][1]=bedict.get(one)\n",
    "        if negative:\n",
    "            fdas.append(i)\n",
    "            i['openie_final'][indexx]=[]\n",
    "    final=[]\n",
    "    for t in i.get('openie_final'):\n",
    "        if t != []:\n",
    "            final.append(t)\n",
    "    i['openie_final']=final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5681f97b-ec3f-497b-91ba-8ab87580c1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fdas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "67e82c12-963a-4199-a826-567595590a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "be=['be','am','is','are','was','were','have been','has been']\n",
    "bedict={}\n",
    "for i in be:\n",
    "    bedict[i]=i\n",
    "can=['can','could','will','would','may','might']\n",
    "candict={}\n",
    "for i in can:\n",
    "    candict[i]=i\n",
    "countt=0\n",
    "counttt=0\n",
    "fdas=[]\n",
    "for i in Relation_raw_all_final_copy:\n",
    "    if i.get('sentence_transformed'):\n",
    "        verblist=sentence2verblist.get(i.get('sentence_transformed'))\n",
    "    else:\n",
    "        verblist=sentence2verblist.get(i.get('sentence'))\n",
    "    verbrelation=''\n",
    "    real_verb=''\n",
    "    verbdict={}\n",
    "    for verb in verblist:\n",
    "        verbdict.update(verb)\n",
    "    for indexx,j in enumerate(i.get('allennlp_final')):\n",
    "        one=j[1]\n",
    "        negative=False\n",
    "        if i.get('sentence_transformed'):\n",
    "            relations=sentence2relations.get(i.get('sentence_transformed'))\n",
    "            verbprototype=sentence2verbprototype.get(i.get('sentence_transformed'))\n",
    "        else:\n",
    "            relations=sentence2relations.get(i.get('sentence'))\n",
    "            verbprototype=sentence2verbprototype.get(i.get('sentence'))\n",
    "        for relation in relations:\n",
    "            if relation[1]==one and negativewords_dict.get(relation[0]):\n",
    "                negative=True\n",
    "        if verbdict.get(one):\n",
    "            verbrelation=one\n",
    "            relations_display=[relation[-2] for relation in relations]\n",
    "            verbprototype_dict={}\n",
    "            for relation in relations:\n",
    "                if relation[1]==verbrelation and negativewords_dict.get(relation[0]):\n",
    "                    negative=True\n",
    "            for verbp in verbprototype:\n",
    "                verbprototype_dict.update(verbp)\n",
    "            for index_passive,passive in enumerate(relations_display):\n",
    "                if passive=='aux:pass':\n",
    "                    if relations[index_passive][1]==verbrelation:\n",
    "                        verb_prototype=verbrelation\n",
    "                        break\n",
    "                elif passive=='acl' and relations[index_passive][-1]=='VBN':\n",
    "                    if relations[index_passive][0]==verbrelation:\n",
    "                        verb_prototype=verbrelation\n",
    "                        break\n",
    "            else:\n",
    "                for v in verbprototype:\n",
    "                    if v.get(verbrelation):\n",
    "                        verb_prototype=v.get(verbrelation)\n",
    "                        break\n",
    "            if verb_prototype!=one:\n",
    "                if countt<10:\n",
    "                    countt+=1\n",
    "            if not negative:\n",
    "                i['allennlp_final'][indexx][1]=verb_prototype\n",
    "        elif bedict.get(one):\n",
    "            if i.get('sentence_transformed'):\n",
    "                relations=sentence2relations.get(i.get('sentence_transformed'))\n",
    "                verbprototype=sentence2verbprototype.get(i.get('sentence_transformed'))\n",
    "            else:\n",
    "                relations=sentence2relations.get(i.get('sentence'))\n",
    "                verbprototype=sentence2verbprototype.get(i.get('sentence'))\n",
    "            for relation in relations:\n",
    "                if relation[1]==one and negativewords_dict.get(relation[0]):\n",
    "                    negative=True\n",
    "            if not negative:\n",
    "                i['allennlp_final'][indexx][1]=bedict.get(one)\n",
    "        if negative:\n",
    "            fdas.append(i)\n",
    "            i['allennlp_final'][indexx]=[]\n",
    "    final=[]\n",
    "    for t in i.get('allennlp_final'):\n",
    "        if t != []:\n",
    "            final.append(t)\n",
    "    i['allennlp_final']=final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25472457-323e-49db-b37d-4cf8ff84d95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fdas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ba78bc16-be4e-4309-87c7-ddbb4604350e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "925"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Relation_raw_all_final_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ac25de-b01c-4c59-bf15-2736d65b0d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "Relation_raw_all_final_copys=[]\n",
    "for i in Relation_raw_all_final_copy:\n",
    "    if i.get('networkx') or i.get('openie_final') or i.get('allennlp_final'):\n",
    "        Relation_raw_all_final_copys.append(i)\n",
    "print(len(Relation_raw_all_final_copys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3961b01-7b3f-43f6-9d38-c7198bc96e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in Relation_raw_all_final_copys:\n",
    "    if i.get('_id'):\n",
    "        del i['_id']\n",
    "json.dump(Relation_raw_all_final_copys,open('results/step3/triplelist.json','w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a705ec2-f4d4-4a91-9d58-c9c97ea1b601",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Relation_raw_all_final_copys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "id": "9f812bf1-f3cd-4ee7-8b48-254087de3aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "collections_Relations_final=db.Relations_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "id": "1cb53b1b-506b-4696-8829-47cb6a3d9c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in Relation_raw_all_final_copys:\n",
    "    i['addtime']=now_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "id": "2ca9236f-5b82-42aa-ad96-bb860dc264c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertManyResult at 0x7f124750e340>"
      ]
     },
     "execution_count": 505,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collections_Relations_final.insert_many(Relation_raw_all_final_copys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "id": "d7b97bd4-210c-497c-8db4-63653e6c4a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(Relation_raw_all_final_copys,open('results/step3/Relation_raw_all_final_copy.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "id": "b9f878d7-a38d-4b85-a2e2-527f692c633a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(Relation_raw,open('results/step3/Relation_raw.pkl','wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hald",
   "language": "python",
   "name": "hald"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
